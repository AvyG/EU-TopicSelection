---
title: "Research Notebook"
author: "Avelyn Garcia, Stephan Pangaanbean, Chris Butcher"
date: "31-05-2023"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# Topic Modeling of the EU State of the Union Speeches
## Research Notebook

#### 1. Introduction

The European Union (EU) is a conglomeration of 27 states with a population of around 447 million people. Given this standing on the world stage, discerning the priorities and concerns of the EU is paramount for understanding its internal and external policies and their impacts.

The State of the Union Address is a speech delivered by the President of the European Commission each September to the Parliament, which "takes stock of the achievements of the past year and presents the priorities for the year ahead" (State of the Union Addresses, n.d.). It was institutionalized in 2010 with the signing of the Framework Agreement on relations between the European Parliament and the European Commission (2010), Annex IV(5).

Up to 2023, 11 speeches have been delivered: four by former President of the Commission José Manuel Barroso (2010-2013), four by former President Jean-Claude Juncker (2015-2018), and three by the current President of the Commission Ursula von der Leyen (2020-2022). Her final speech for the current mandate is scheduled for this September. During European parliamentary elections, no address is delivered.

The primary objective of this research notebook is to explicate and analyze the key topics of these speeches, as they offer a transparent window into the priorities of European politics and its temporal changes.

This research notebook is organized into 8 sections. Section 2 describes and demonstrates how we scrape part of our data. Section 3 details the preprocessing and cleaning of the speech text. Section 4 presents a descriptive analysis of the text. Section 5 introduces our LDA model and the selection of its hyperparameters. Section 6 discusses the validation of our model and some limitations of our research. Finally, Section 7 presents our conclusions, followed by a brief 'elevator pitch' in the last section.

-------------------------------------------------------------------------
Disclaimer: ChatGPT 3.5/4.0 was used in this project, primarily in the following capacities:

- Advanced Search Engine
  We used ChatGPT to ask various questions, such as:
  "Can you give me models for topic analysis?", "Can you give me the strengths and weaknesses of each model?", "and what does htmltools?", "Assume there is a [matching] vector with [the] main themes, how can I [concatenate] my vectors to the matrix?"
  or including questions about specific errors encounter while coding. For example:
  "Why do I have this error
Warning: package ‘tidyverse’ was built under R version 4.2.3Warning: package ‘ggplot2’ was built under R version 4.2.3Error: package or namespace load failed for ‘tidyverse’:[...], [What is happening?]"
   or
  "I get the following error
Error: '\s' is an unrecognized escape in character string starting ""^(STATE OF THE    UNION|State of the Union) [0-9]{4}[\n\s""
  
- Code Copilot
  At times, we used ChatGPT to suggest how to perform a task or how to improve existing code. For example:
  "and if I [want to] save multiple attributes from my webpage like name, link, description block if exists[,] how can I do it?"
  or
  "I am trying to remove the following text from different speeches [give an example of the text,] can you give me a regular expression that eliminate this strings"
  or
  "I am using pdf_speech <- sub("^\\s*State of the Union [0-9]{4}\\s*[\\sA-Za-z\\s-]*",     "----------", pdf_speech) but a better Europe does not count in my regular 
  
- Text Corrector
  We give a piece of written text like paragraphs of the introductions and other sections and then ask chatGPT to check for coherence and formality of our text.
  In an intent to avoid plagarism, we conditioned the use of this function as to always give a text made from the students as input to the algorithm.
  For example: "Can you check for coherence and formality this text?
  From our scrapping we can see that there has been a evolution of main topics across time. The first speeches are mainly about the economic shape of the European union, to then mainly talk about economic recuperation mixed with the migration crisis and investment across multiple industries to finally focus about the pandemic, health and the Ukraine war."


The text in square brackets represents either grammatical corrections or added text for clarity. If there are any questions, please send an email to any of the students (for example: avelynfernanda.garciaaraya@student.kuleuven.be).

-------------------------------------------------------------------------

#### Libraries

This are the libraries our project used

```{r libraries, warning=FALSE}
# Decomment this if you want to install any of the packages
#install.packages(c("rvest","tidyverse","httr","pdftools","quanteda", "wordcloud","topicmodels","textstem", "tidytext", "topicdoc"))

library(httr)
library(pdftools)
library(rvest)
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
library(wordcloud)
library(topicmodels)
library(textstem)
library(tidytext)
library(topicdoc)

```

#### 2. Data Colection

In our project, we will focus on two primary data sources:

1. The keywords associated with each speech. These keywords are extracted from the official website. We will use these keywords for validation purposes.

2. The PDFs containing the actual speeches: We have decided to manually download each speech to ensure their relevance. Specifically, we wanted to be sure that the documents are in English only and that they correspond to the correct year. For instance, we found that attempting to access the 2020 speech online would redirect to the 2021 speech.

In this section, we outline our process for scraping the main topic keywords associated with each speech. We will start by scraping the keywords of speeches given by the current president. Subsequently, we will perform the same process for speeches given by the two preceding presidents.


```{r crawling identification}

# We identify ourselves

httr::set_config(httr::user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:113.0.2) Gecko/20100101 Firefox/113.0.2 (scrapping EU speeches and keywords for a homework <3, thank you for your patience)"))

```


```{r keywords_current_president1}

# Specify the original url from which we will index and scrap the speeches
base_url <- 'https://state-of-the-union.ec.europa.eu/index_en'

webpage <- read_html(base_url)

```


```{r keywords_current_president2}

# Extract the key words from the speeches of the current president
name_speech <- webpage %>% 
              html_nodes("h1.ecl-content-block__title") %>%
              html_nodes(".ecl-link.ecl-link--standalone") %>%
              html_text()
name_speech <- head(name_speech,-5)

links <- webpage %>% 
              html_nodes("h1.ecl-content-block__title") %>%
              html_nodes(".ecl-link.ecl-link--standalone") %>%
              html_attr("href")
links <- head(links,-3)

description_speech <- webpage %>% 
                      html_nodes("div.ecl-content-block__description") %>%
                      html_nodes(".ecl") %>%
                      html_text()

df <- data.frame(name_speech = name_speech, main_topics = description_speech)
df

```


``` {r keywords_previous_presidents1}

# Extract the key words from the speeches of previous presidents
# To be a good bot, we add a small delay time, even if https://ec.europa.eu/robots.txt and https://state-of-the-union.ec.europa.eu/robots.txt do not indicate the necessity of one.

base_url <- 'https://state-of-the-union.ec.europa.eu'
full_urls <- paste(base_url, tail(links,2),sep='')

pages <- lapply(full_urls, function(u) {
   wp <- read_html(u)
   Sys.sleep(11)
   return(wp)
})

```

```{r keywords_previous_presidents2}

# Get the speech keywords from the speeches of the previous two presidents (Run the cell altogether)

# Find the components of interest
descriptions_speech <- lapply(pages, function(pages) html_nodes(pages, "div.ecl p"))
names_speech <- lapply(pages, function(pages) html_nodes(pages, "div.ecl h3"))

# Convert them into text
descriptions_speech <- lapply(descriptions_speech, html_text)
names_speech <- lapply(names_speech, html_text)

# Clean the element of description (there is extra info)
descriptions_speech <- lapply(descriptions_speech, function(x) x[!grepl("Address \\| Video", x)])

# Unlist element to save them in a ddf
descriptions_speech <- unlist(descriptions_speech)
names_speech <- unlist(names_speech)

# And add these keywords to a matrix to save them
temp_df <- data.frame(name_speech = names_speech, main_topics = descriptions_speech)
df <- bind_rows(df, temp_df)

# Create new columns year and speech_text
df <- df %>% mutate(year = sub(".*\\b(\\d{4})$", "\\1", name_speech),
                    speech_text = NA)
df

```

```{r save data}
# We save the data to avoid calling the scrapper all the time
save.image("df_keywords.RData")

```

Our scraping results illustrate an evolution of main topics over time.

Initial speeches primarily focused on the economic condition of the European Union. This then shifted to discussions about economic recovery, intertwined with the migration crisis and investment across various industries. More recent speeches have pivoted to addressing the COVID-19 pandemic, health issues, and the conflict in Ukraine.


#### 3. Preprocessing

Firstly, as previously mentioned, we manually downloaded the PDF files of interest, which are included alongside this notebook. This step was taken to ensure the quality and suitability of our text.

We noted that some PDFs contained extra information, irrelevant to our purposes, which varied depending on the document's format. This unnecessary information, which is not pertinent to our analysis, include:

- Speech covers
- Page numbers
- Titles and subtitles
- Preambles
- Images
- Closing statements

We've made efforts to clean the text to preserve as much of the actual spoken speech as possible.

```{r readpdfs}
path_to_folder <- "./PDFs/"

pdf_files <- list.files(path = path_to_folder, pattern = "\\.pdf", full.names = TRUE)

for (pdf_file in pdf_files){
  pdf_speech <- pdf_text(pdf_file)
  par_year <- regmatches(pdf_speech, regexpr("September\\s*(\\d{4})|STATE OF THE UNION\\s*(\\d{4})", pdf_speech))
  par_year <- par_year[1]
  par_year <- str_sub(par_year,-4,-1)

  # pdf_text returns an element for each page, we already know that the 2016 document include more texts than the speech. Even if we can erase the rest of the text in a later step, for simplicity we will do it now
  
  if(par_year == "2016"){pdf_speech <- pdf_speech[1:22]}
  
  # Clean the page number (easier to do it before the merging of pages)
  pdf_speech <- sub("\\s*\\d+\\s*(\\n)+$", " ", pdf_speech)
  
  # Clean the header if exist
  pdf_speech <- sub("^\\s*State of the Union [0-9]{4}\\s*.*?\\n{4,}", "\n", pdf_speech, ignore.case = TRUE, perl = TRUE)
  
  # Collapse the pages
  speech_joint <- paste(pdf_speech, collapse =" ")
  
  # Clean 's
  speech_joint <- gsub("’s|'s", " ", speech_joint, ignore.case = TRUE)
  
  # Clean titles (2015 is not possible because our expression eraised part of the speech)
  if (par_year %in% c("2012")){
    speech_joint <- gsub("\\n{2,}\\d+\\s*\\.[A-Za-z:\\s'\\-\\—\\–]+\\n|\\n{2,}\\s*[a-z]\\) [A-Za-z\\s:'\\-\\—\\–]+\\n", "\n", speech_joint, perl = TRUE)
    }
  else if (par_year %in% c("2016","2017","2018","2020")){
    speech_joint <- gsub("\\n{1,}[A-Z:\\-\\—\\–\\s]+\n{1,}", "\n", speech_joint, perl = TRUE) 
  }
  else if (par_year %in% c("2021","2022")){
    speech_joint <- gsub("\\n{3,}[A-Z][A-Za-z\\s]+\\n{1,}", "\n", speech_joint, perl = TRUE) 
  }
  
  # Clean punctuation
  speech_joint <- gsub("[[:punct:]]", " ", speech_joint)
  
  # Clean preamble
  speech_joint <- sub(".*?(Mr President|Dear President|President \nHonourable Members|Mr  President)", " ", speech_joint)

  # Clean finisher
  speech_joint <- sub("(SPEECH|Updated version following delivery|For further information| Jean Claude Juncker).*", "", speech_joint)
  
  # Clean repetitive addresses to public
  speech_joint <- gsub("Presidency of the Council|Madam President of the Council|Dear Mr President|Dear President|Mr President|Madam President|Honourable Members of the European Parliament|Honourable Members|Honourable members|Minister|Ladies and Gentlemen|Ladies and gentlemen|My fellow Europeans|My dear colleagues", " ", speech_joint)
  
  # Clean spaces
  speech_joint <- gsub("\\s+", " ", speech_joint)
  
  # Match the speech with its year
  df$speech_text[df$year == par_year] <- speech_joint
  
}

df <- as_tibble(df)
df

```

In addition to the situations mentioned earlier, we further cleaned the text by removing punctuation and extra spaces before saving it to our dataframe. We would like to bring attention to some issues that arose during this process:

- The 2016 speech includes some images with text that is read by the 'read_pdf' command. We attempted to remove this, but it proved challenging without discarding portions of the speech that are relevant to our analysis. Consequently, we opted to retain this additional text. Since the images are related to the speech, they should not significantly skew our analysis of the speech's primary topic.

- We made a deliberate choice to remove certain frequently repeated words that did not contribute valuable information for our purposes. Phrases such as "Mr President" and "Honourable members" appear so frequently in the speeches that they could potentially confuse topic models by appearing as significant topics.

- Additionally, we decided to eliminate the contraction "'s" as it does not contribute significantly to topic selection.

To complete the preprocessing of our texts, we tokenized, lemmatized, and removed stopwords to refine our results.

```{r textstem}

custom_stopwords = c(stopwords("en"))

speech_tokens <- df$speech_text %>%  tolower() %>%
                        lemmatize_strings() %>%
                        corpus() %>%
                        quanteda::tokens() %>%
                        quanteda::tokens_remove(custom_stopwords)

speech_tokens

```


### 4. Descriptive Analysis

Before the application of the topic models, it would be beneficial to examine in greater detail the text data we have extracted from the speeches.

Initially, we will visualize the most frequently used words across all speeches. This exploration may provide valuable insights to guide us in determining the number of topics to be identified in subsequent steps or indicate if our data requires further refinement.

```{r}

dfm_matrix <- speech_tokens %>% dfm()

textstat_frequency(dfm_matrix)[c(1:50),]

tail(textstat_frequency(dfm_matrix), 50)

```

Many of the most frequent words in our dataset do not substantially contribute to understanding the main topics of the speeches. These words are often more related to the intent or style of a speech rather than the core message. For example, the words "must" and "can" are typically used to express present or future intent, an expected finding since one of the primary functions of these speeches is to outline priorities for the upcoming year. Moreover, terms such as "europe", "european", and "union" are prevalent due to the inherent context of the speech, yet they do not necessarily elucidate the central topics.

Such observations prompt us to eliminate some of the most commonly occurring, yet non-informative, words from the text.

```{r}

custom_stopwords = c(stopwords("en"), "europe", "european","eu","much","can","state","union","make","year","also","must","need","commission", "member")

new_tokens <- speech_tokens %>% 
              quanteda::tokens_remove(custom_stopwords)

new_dfm <- new_tokens %>% dfm()

textstat_frequency(new_dfm)[c(1:50),]

```

Now, with our refined bag of words, we will conclude our descriptive analysis by creating a word cloud for each speech. This will allow us to visually represent the most prominent ideas expressed in each individual speech.

```{r wordcloud for each speech}

# Assuming df is your data frame and speech_text is the column containing speeches
for (i in 1:length(new_tokens)){
  
  dfm_matrix <- new_tokens[i] %>% dfm()
  textplot_wordcloud(dfm_matrix, max_words = 35)
  title(main = paste("Word Cloud for State of the Union", df$year[i]))
}

```

From the word clouds, we can observe apparent differences between speeches:

- 2022: The focus is primarily on "ukraine" and related terms ("war", "crisis", "ukrainian", "russia"). There are also words connected to the "economy" ("price", "gas"), along with "democracy", and some words that are more ambiguous in their classification such as "solidarity", "future", "global", "people", "support".

- 2021: Frequent words include some generic terms ("new", "time", "world", "global", "work", "together"), economic terms ("market", "investment"), and the words "pandemic", "freedom", and "climate", which all could be linked to the generic words.

- 2020: Again, generic words like "world", "want", "work", and "people" appear, in addition to some words indirectly related to the pandemic ("digital", "strong", "together").

- 2018: Repeated words include more ambiguous ones ("world", "good", "today"), economic terms ("investment","trade"), and new words like "election", "Africa", and "border", to name a few.

- 2017: Frequently seen words are "want", "good", "work", "now", "new", etc. Identifying clear connections among words in this speech is challenging.

- 2016: Frequent words include "work", "get", "take", "job", "parliament", etc. Establishing clear connections among words in this speech is also difficult.

- 2015: Some recurring themes like "greece", "euro", and "crisis" are present, along with a clear new cluster of "refugee" ("asylum") and the words "policy" and "climate".

- 2013: The main words are "crisis", "one". The economic cluster of words ("market", "euro", "economy", "economic") is very prominent.

- 2012: The word "political" is predominant, along with clusters of ideas related to "economics" ("bank","market","euro") and "reform" ("change", "decision", "way").

- 2011: The focus is on "economic/economy"-related words ("market", "growth", "financial"), with related terms such as "euro" and "greece".

- 2010: This speech primarily contains words related to economics ("budget", "financial", "growth", "job", "market").

Overall, we see that all speeches maintain an economic aspect, which is noticeably more prominent in older speeches (2010-2012) and the most recent speech (2022). Additionally, we observe a cluster of words related to migration ("refugee", "border") appearing in 2015 and 2018, fading in 2020 with the advent of COVID-19 and the war in Ukraine (and their associated economic crises). The speeches from 2016 and 2017 present some challenges when it comes to precise topic identification.

Despite these observations, our findings are consistent with the main themes extracted from the official websites and recent European history.

We have intentionally excluded certain words, such as "us", from our analysis because of their potential multiple meanings. Additionally, the word cloud reveals potential issues with our text cleaning process. For instance, the words "t", "1", and "2" occasionally appear in the clouds, along with nearly identical terms like "economic" and "economy". A more thorough explanation is provided in the Validation section.


```{r savedata1}
# Save the data 
save.image("savedata.RData")

```


#### 5. Topic Modeling

One of the most widely used techniques for topic modeling is the Latent Dirichlet Allocation (LDA) model. LDA is a mixture model; in other words, it assumes that each document is a mixture of topics, and each topic is a blend of words that are not exclusive to that topic. Given these assumptions, the model strives to determine the topic for each word in the documents.

In this section, we adopt code from Van Atteveldt, W., et al. (2022, Chapter 11) for the implementation of the LDA model and the search for hyperparameters. We also used code from Silge J. & Robinson D. (2017, Chapter 6) for the visualization the topics per document.

Initially, we opted to execute a grid search to determine the optimal number of topics (k). We set the value of alpha to an asymmetric vector following the formula alpha = 1/(n + sqrt(k)) (Van Atteveldt, W., et al., 2022, Chapter 11)), where 'n' ranges from 1 to k. Our choice for an asymmetrical alpha stems from the expectation that certain topics may appear more frequently in specific speeches than in others. For instance, should the topics "pandemic" or "health" arise, we anticipate these to be more prevalent in the three most recent speeches (2020-2022) compared to the others.

We fitted our LDA models using different values of k, ranging from 3 to 30. While this range might seem arbitrary, it is justified considering that the maximum number of keywords scraped from the main topics is 9. If we interpret each keyword as a topic, the range is sufficient for finding an optimal quantity of topics. The metrics we will use to define this optimal point are Perplexity and Coherence of the model. Perplexity evaluates how well the model predicts the word distribution, and Coherence assesses the semantic cohesiveness of the topics. In general, we are seeking the model that minimizes both these metrics.

```{r LDA}
# LDA for all speeches together (this ~30 mins, beware running this cell)

# Create vector for k
k_lda <- seq(3,30)
results <- list()

dfm_matrix <- new_tokens %>% dfm()
dtm <- dfm_matrix %>% convert(to = "topicmodels")


# Loop to test configuration of hyperparameters
for (k in k_lda){
  
  iteration_results <- list()
  alpha = 1/((1:k)+sqrt(k))
  
  for (i in 1:10){

  cat("Model k=", k, " iteration=", i, "\r")
  
  lda_model <- dfm_matrix %>%
               convert(to = "topicmodels") %>% 
               LDA(k=k, control = list(alpha=alpha))
  
  iteration_results[[as.character(i)]] <- data.frame(
                              perplexity = perplexity(lda_model),
                              coherence = mean(topic_coherence(lda_model, dtm)))
  
  }
  
  avg_perplexity <- mean(sapply(iteration_results, function(x) x$perplexity))
  avg_coherence <- mean(sapply(iteration_results, function(x) x$coherence))
  
  results[[as.character(k)]] <- data.frame(
                                perplexity <- avg_perplexity,
                                coherence <- avg_coherence)

}

bind_rows(results, .id="k") %>% 
  mutate(k=as.numeric(k)) %>%
  pivot_longer(-k) %>% 
  ggplot() + 
  geom_line(aes(x=k, y=value)) + 
  xlab("Number of topics") + 
  facet_grid(name ~ ., scales="free")

 
```

We can see that the model with the lowest value in both metrics is k=17. Once we define the model we will use, we can check the topics extracted.


```{r}
k <- 17

lda_k17 <- dfm_matrix %>%
           convert(to = "topicmodels") %>% 
           LDA(k=k, control = list(seed=0, alpha=1/((1:k)+sqrt(k))))

terms(lda_k17, 10)

```

When we are interpreting topics from our model certain topics are quite apparent.

For instance, Topic 3 is clearly about Ukraine and its ongoing war. Topics 7, 8, 10, and 11 concern economic matters, but from different perspectives. Topic 7 appears to focus on the growth of the internal EU market, while Topic 8 seems to address policy or reforms following an economic crisis. Topic 10 seemingly centers around protecting investment during a crisis in the eurozone, and Topic 11 looks to be related to economic growth, particularly in response to a crisis.

Another clearly distinguishable topic is Topic 15, which pertains to the refugee crisis. This could potentially refer to the lasting effects of the euro economic crisis in Greece or the refugee crisis specifically affecting Greece.

The remaining topics are somewhat ambiguous, making interpretation challenging. A clear central idea does not readily emerge from the associated bag of words.

```{r savedata}
# Save the data 
save.image("savedata.RData")

```


#### 6. Validation

To evaluate the performance of our model, we will compare the words from the most representative topics identified in the speeches with the primary theme that we extracted from the official website.


```{r}

documents_gamma <- tidy(lda_k17, matrix = "gamma")

df_wide <- documents_gamma %>% 
           unite(topic, topic, sep=" ", remove=FALSE) %>%
           spread(key=topic, value=gamma)
df_wide$doc_num <- as.numeric(gsub("text", "", df_wide$document))
df_wide <- df_wide[order(df_wide$doc_num), ]
df_wide$doc_num <- NULL

# Find the columns which are numeric
num_cols <- which(sapply(df_wide, is.numeric)) 
df_wide[, num_cols] <- round(df_wide[, num_cols], 3)

# Column order
order_col <- c("document", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17")

df_wide <- df_wide %>% select(all_of(order_col))
df_wide

```

We now contrast the results of our model with the main themes of the speeches extracted for each document:

- Text1 (2022 Speech): This text belongs solely to Topic 3, the primary words of which are "us", "today", "ukraine", "market", "time", "future", "war", "new", "democracy", and "good". In comparison to the main topics extracted from the website (EU support for Ukraine, overcoming the energy crisis, climate, rule of law, democracy, support for European enterprises), there is a clear overlap, particularly in areas like Ukraine and democracy. However, key topics such as climate, law, and energy are absent from the bag of words that best represent this text. Consequently, our model does not fully capture some of the speech's characterization.

- Text 2 (2021 Speech): This speech can be categorized into multiple topics. Approximately 82% of the speech's words are associated with Topic 5, which includes key terms such as "new", "time", "global", "world", "good", "value", "work", "people", "together", and "us". The remaining 18% of words pertain to Topic 10, with keywords such as "market", "investment", "freedom", "level", "common", "crisis", "defend", "work", "end", and "euro". When we compare these findings with the main themes extracted from the website - which include COVID-19, global health, vaccination, a stronger Europe in the world, the European Chips Act, the European Defence Union, rule of law, and media freedom - it seems that Topic 5 primarily represents the pandemic topic in a more cooperative context, whereas Topic 10 focuses on investment plans for Europe. Nonetheless, key themes such as law and media are notably absent from the bag of words that best represent this speech. 

- Text 3 (2020 Speech): This speech falls under multiple categories. Roughly 30% of the speech's words pertain to Topic 2, which includes "people", "new", "get", "support", "global", "us", "way", "opportunity", "show", and "take". Approximately 49% of the words are associated with Topic 6, which comprises "world", "us", "work", "want", "good", "time", "together", "datum", "change", and "build". The remaining 21% of words correspond to Topic 9, featuring "just", "first", "world", "energy", "life", "always", "new", "global", "show", and "us". When we juxtapose these findings with the main themes identified from the website - which include the COVID-19 pandemic, NextGenerationEU, European Health Union, Industrial Strategy, Europe’s Digital Decade, and the New European Bauhaus - the results prove unsatisfactory. The only words from our model's topic selection that bear any relation to the speech's primary themes have an indirect connection with the pandemic, such as "global", "together", and "support". Consequently, we conclude that the model did not perform adequately in identifying the main themes of this speech.   

- Text 4 (2018 Speech): This speech falls under multiple categories. Approximately 23% of the speech's words are associated with Topic 13, which includes "good", "work", "solidarity", "right", "long", "love", "new", "2019", "always", and "day". Meanwhile, 77% of the speech's words pertain to Topic 16, with words such as "one", "time", "world", "come", "want", "today", "unite", "us", "border", and "speak". When we compare these findings with the main themes extracted from the website - namely migration, cybersecurity, and foreign policy - we notice that, aside from the word "border", there is no significant overlap between our main topics and the official main themes. Therefore, we conclude that the model did not effectively categorize this speech.

- Text 5 (2017 Speech): This speech spans across multiple categories. About 39% of the speech's words are associated with Topic 12, with words such as "new", "good", "work", "president", "area", "parliament", "want", "rule", "propose", and "law". Around 7% of the words are linked to Topic 13, which includes "good", "work", "solidarity", "right", "long", "love", "new", "2019", "always", and "day". Meanwhile, 54% of the speech's words pertain to Topic 14, with words such as "want", "now", "last", "single", "take", "parliament", "strong", "people", "democratic", and "today". Upon comparison with the main themes extracted from the website — namely united, stronger and more democratic union, trade, investment screening, cybersecurity, industry, data and democracy — there is a modest overlap with some of the most frequent words in the topics, such as "strong", "democratic" and "rule". However, this overlap is quite minimal, suggesting that in this instance, the topics do not cover all the principal themes of the speech.

- Text 6 (2016 Speech): This speech pertains solely to Topic 17, characterized by keywords such as "work", "take", "get", "job", "parliament", "world", "billion", "mean", "want", and "today". When compared with the main themes extracted from the website — including investments in youth, jobseekers and start-ups, public Wi-Fi access, fairer copyright laws, the Investment Plan for Africa, and the new European Border and Coast Guard — it's challenging to establish a clear relationship between the selected topic and the official themes of the speech.

- Text 7 (2015 Speech): This speech falls under multiple categories. Primarily, 96% of the speech's words belong to Topic 15, with keywords such as "refugee", "euro", "Greece", "crisis", "time", "area", "president", "today", "want", and "work". Additionally, 4% of the words align with Topic 12, which features "new", "good", "work", "president", "area", "parliament", "want", "rule", "propose", and "law" as its key words. When compared with the main topics extracted from the website, which include the emerging refugee crisis, the future of the Euro, foreign policy, migration, external action, and economic and fiscal policy, the association with Topic 15 is quite evident. The link to Topic 12 seems to stem from common words shared between the topics. 

- Text 8 (2013 Speech): This speech belongs to multiple categories. Primarily, 87% of the speech's words are associated with Topic 4, which includes key terms such as "one", "crisis", "country", "people", "market", "together", "us", "way", "come", and "time". Additionally, 13% of the speech's words align with Topic 11, characterized by "economic", "growth", "budget", "crisis", "financial", "job", "now", "us", "area", and "euro". When compared with the main topics extracted from the website, which encompass economic recovery, European integration, deepening of the Economic and Monetary Union, and the European elections of 2014, the association with both topics seems reasonable. The greater relation to Topic 4 is also expected, given its more uplifting words, which are typical in a speech about recovery. Nevertheless, just as with previous speeches, the selected topics do not cover the entire range of themes present in the speech.

- Text 9 (2012 Speech): This speech belongs solely to the Topic 8 category, characterized by main words such as "political", "economic", "mean", "bank", "crisis", "country", "reform", "debate", "world", and "today". When compared to the main topics extracted from the website — 'A New Thinking for Europe', 'Decisive Deal for Europe', 'Treaty Change', '17/27 Dimension', and 'Expanding Public Debate' — it might appear at first glance that the selected topic is unrelated to the main themes. However, upon closer inspection, it becomes evident that the main themes we extracted are actually subtitles of the speech. When we consider the content of the speech itself, Topic 8 emerges as a more reasonable selection for the central theme. 

- Text 10 (2011 Speech): This speech belongs to multiple categories. Predominantly, 94% of the words of the speech belong to Topic 7 ("world", "euro", "market", "growth", "area", "today", "us", "financial", "proposal", "economic"), while 6% belongs to Topic 10 ("market", "investment", "freedom", "level", "common", "crisis", "defend", "work", "end", "euro"). Compared to the main topics extracted from the website, which include the financial transaction tax (FTT), eurozone bond, economic crisis, and defence sector integration, the topic selections from our model are reasonable, as they overlap well with the main themes of the speech. 

- Text 11 (2010 Speech): This speech falls into multiple categories. Predominantly, 70% of the words in the speech belong to Topic 1 ("growth", "see", "world", "common", "new", "action", "job", "proposal", "energy", "market") and 30% of the words belong to Topic 11 ("economic", "growth", "budget", "crisis", "financial", "job", "now", "us", "area", and "euro"). Compared to the main topics extracted from the website (EU Economic governance, growth, freedom, security, and justice, EU Budget, and the EU on the global stage), both topics are related to the main themes of the speech. However, neither of the topics mentions security or justice, so these themes are not represented in our topics.

In conclusion, our model can appropriately select the topic of some speeches. Primarily, for the speeches of 2022, 2021, 2015, 2013 and 2010, the topic selection was closely related to the expected main theme. However, in the remaining speeches, the lack of correlation between the selected topics and the main themes of the speeches was disappointing."

There could be several reasons for these results. Thus, we would like to dedicate the final part of this section to discussing the shortcomings of our methodology.

- Firstly, we would like to address the cleaning issues mentioned in section 4. Words such as "us" can have ambiguous meanings as they could refer to the pronoun 'us' or be an acronym for 'United States' in lowercase. As one can see, these two uses have entirely different implications, but in our study, we unintentionally combined them. One way to deal with this would be to lowercase only words that begin with a capitalized letter. 

- Another issue we perceived during our descriptive analysis was the presence of non-informative words such as "t", "1", and "2". Their presence indicates that our cleaning process was not as thorough as it should have been. It is well-known that for topic analysis, the results are extremely sensitive to the cleaning regime. 

- Aside from cleaning issues, we also noted limitations to the validity of our model due to decisions we made during the fitting step. One such decision was that we only searched for optimal 'k', neglecting 'alpha', which is an important hyperparameter that influences the model and its results. We recognize that for future steps, it is important to optimize 'alpha' in the same manner we did for 'k'.

- Also, during the fitting step, we only iterated the fitting process of the LDA model 10 times. This was due to the computational time the code requires for fitting multiple models. However, we recognize that such a low number of iterations makes it difficult for our metric to converge to its real result, potentially skewing our decision on which model is most appropriate. In future iterations of this work, it would be ideal to increase this value until we are certain of convergence.

- Furthermore, to more seriously address the validation process of our model, it would be ideal to use additional models such as the Structural Topic Model (STM) or Dynamic Topic Models (DTM). The latter is particularly interesting to us since the model is designed to handle documents that evolve over time. Using other models would provide us with additional comparison points for the topics suggested by our models, thereby strengthening the final decision on the most appropriate model.



#### 7. Conclusions

However as we previously stated in the validation section, there are multiple challenges to 




#### 8. Elevator Pitch






#### 9. References

State of the Union addresses. (n.d.). State of the Union. https://state-of-the-union.ec.europa.eu/index_en

Framework Agreement on relations between the European Parliament and the European Commission, EP, 304 OJ L (2010). http://data.europa.eu/eli/agree_interinstit/2010/1120/oj/eng

von der Leyen, U. (n.d.). State of the Union Address 2022. State of the Union . https://state-of-the-union.ec.europa.eu/system/files/2023-06/SOTEU_2022_Address_EN.pdf 

von der Leyen, U. (n.d.-a). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_21_4701 

von der Leyen, U. (n.d.-b). State of the Union Address 2020. State of the Union 2020. https://state-of-the-union.ec.europa.eu/system/files/2022-08/soteu_2020_en.pdf 

Juncker, J. C. (n.d.). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/speech_18_5808 

Juncker, J. C. (n.d.-b). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_17_3165 

European Commission, Directorate-General for Communication, Juncker, J. (2016). State of the Union 2016 – , Publications Office of the European Union. https://data.europa.eu/doi/10.2775/968989

Juncker, J. C. (n.d.-c). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_15_5614 

Barroso, J. M. (n.d.). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_13_684

Barroso, J. M. (n.d.-b). Press corner.European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_12_596

Barroso, J. M. (n.d.-c). Press corner.European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_11_607

Barroso, J. M. (n.d.-d). Press corner.European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_10_411

Van Atteveldt, W., Trilling, D., & Calderón, C. A. (2022). Computational Analysis of Communication. Wiley Blackwell. Retrieved June 18 2023 from https://cssbook.net/content/chapter11.html#sec-beyondlda 

Silge J. & Robinson D. (2017). Text mining with r : a tidy approach (First). O'Reilly Media. Retrieved June 18 2023 from https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=1533983.








