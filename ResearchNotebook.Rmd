---
title: "Research Notebook"
author: "Avelyn Garcia, Stephan Pangaanbean, Chris Butcher"
date: "31-05-2023"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# Topic Modeling of the EU State of the Union Speeches
## Research Notebook

#### 1. Introduction

The European Union (EU) is a conglomeration of __ states with a population of __ million people making it the __ most important economy in the world, behind countries like ___. For this position in the world stage, determining the priorities and concerns that the EU had or has is paramount to understand its internal and external policy and its impact.

The State of the Union Address is an speech deliver by the President of the European Commission each September to the Parliament that "takes stock of the achievements of the past year and presents the priorities for the year ahead" (State of the Union Addresses, n.d.). It was institutionalized in 2010 with the signed of the Framework Agreement on relations between the European Parliament and the European Commission (2010), Annex IV(5).

(add examples of researchers that have study state of the union speeches)

Up to 2023, 11 speeches have been delivered, four by former President of the Commission José Manuel Barroso (2010-2013), four by former President President Jean-Claude Juncker (2015-2018) and three by current President of the Commission Ursula von der Leyen (2020-2022) with her last speech for the current mandate scheduled for this September. During European parliamentary elections, no address is deliver. 

The main objective of this research notebook is to explain and analysis the main topics of these speeches as they provide a transparent window into the priorities of the European politics and its changes across time.

This research notebook is organized in __ sections.

-------------------------------------------------------------------------
Disclaimer: chatGPT 3.5/4.0 was used in this project. The main uses during the project were: 

- Advanced Search Engine
  We used chat GPT to ask questions like:
  "Can you give me models for topic analysis?", "Can you give me the strengths and weaknesses of each model?", "and what does htmltools?", "Assume there is a [matching] vector with [the] main themes, how can I [concatenate] my vectors to the matrix?"
  or
  Including questions about specific errors encounter while coding. For example:
  "Why do I have this error
Warning: package ‘tidyverse’ was built under R version 4.2.3Warning: package ‘ggplot2’ was built under R version 4.2.3Error: package or namespace load failed for ‘tidyverse’:[...], [What is happening?]"
   or
  "I get the following error
Error: '\s' is an unrecognized escape in character string starting ""^(STATE OF THE    UNION|State of the Union) [0-9]{4}[\n\s""
  
- Code Copilot
  In some instances, we used chatGPT to suggest how to perform a task or how improve existing code. For example:
  "and if I [want to] save multiple attributes from my webpage like name, link, description block if exists[,] how can I do it?"
  or
  "I am trying to remove the following text from different speeches [give an example of the text,] can you give me a regular expression that eliminate this strings"
  or
  "I am using pdf_speech <- sub("^\\s*State of the Union [0-9]{4}\\s*[\\sA-Za-z\\s-]*",     "----------", pdf_speech) but a better Europe does not count in my regular 
  
- Text Corrector
  Give a piece of written text like paragraphs of the introductions and other sections to then ask chatGPT check for coherence and formality.
  In an intent to avoid plagarism, we conditioned the use of this function as to always give a text made from the students as input to the algorithm.
  For example: "Can you check for coherence and formality this text?
  From our scrapping we can see that there has been a evolution of main topics across time. The first speeches are mainly about the economic shape of the European union, to then mainly talk about economic recuperation mixed with the migration crisis and investment across multiple industries to finally focus about the pandemic, health and the Ukraine war."


The text in between [] are either grammatical corrections or adding text to clarify the example. If there are any question, please send an email to any of the students (for example: avelynfernanda.garciaaraya@student.kuleuven.be).

-------------------------------------------------------------------------

#### Libraries

This are the libraries our project used

```{r libraries, warning=FALSE}
# Decomment this if you want to install any of the packages
#install.packages(c("rvest","tidyverse","httr","pdftools","quanteda", "wordcloud","topicmodels","textstem", "tidytext", "topicdoc"))

library(httr)
library(pdftools)
library(rvest)
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
library(wordcloud)
library(topicmodels)
library(textstem)
library(tidytext)
library(topicdoc)

```

#### 2. Data Colection

In our project, we will focus on two primary data sources:

1. The keywords associated with each speech. These keywords are extracted from the official website. We will use these keywords for validation purposes.

2. The PDFs containing the actual speeches: We have decided to manually download each speech to ensure their relevance. Specifically, we wanted to be sure that the documents are in English only and that they correspond to the correct year. For instance, we found that attempting to access the 2020 speech online would redirect to the 2021 speech.

In this section, we outline our process for scraping the main topic keywords associated with each speech. We will start by scraping the keywords of speeches given by the current president. Subsequently, we will perform the same process for speeches given by the two preceding presidents.


```{r crawling identification}

# We identify ourselves

httr::set_config(httr::user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:113.0.2) Gecko/20100101 Firefox/113.0.2 (scrapping EU speeches and keywords for a homework <3, thank you for your patience)"))

```


```{r keywords_current_president1}

# Specify the original url from which we will index and scrap the speeches
base_url <- 'https://state-of-the-union.ec.europa.eu/index_en'

webpage <- read_html(base_url)

```


```{r keywords_current_president2}

# Extract the key words from the speeches of the current president
name_speech <- webpage %>% 
              html_nodes("h1.ecl-content-block__title") %>%
              html_nodes(".ecl-link.ecl-link--standalone") %>%
              html_text()
name_speech <- head(name_speech,-5)

links <- webpage %>% 
              html_nodes("h1.ecl-content-block__title") %>%
              html_nodes(".ecl-link.ecl-link--standalone") %>%
              html_attr("href")
links <- head(links,-3)

description_speech <- webpage %>% 
                      html_nodes("div.ecl-content-block__description") %>%
                      html_nodes(".ecl") %>%
                      html_text()

df <- data.frame(name_speech = name_speech, main_topics = description_speech)
df

```


``` {r keywords_previous_presidents1}

# Extract the key words from the speeches of previous presidents
# To be a good bot, we add a small delay time, even if https://ec.europa.eu/robots.txt and https://state-of-the-union.ec.europa.eu/robots.txt do not indicate the necessity of one.

base_url <- 'https://state-of-the-union.ec.europa.eu'
full_urls <- paste(base_url, tail(links,2),sep='')

pages <- lapply(full_urls, function(u) {
   wp <- read_html(u)
   Sys.sleep(11)
   return(wp)
})

```

```{r keywords_previous_presidents2}

# Get the speech keywords from the speeches of the previous two presidents (Run the cell altogether)

# Find the components of interest
descriptions_speech <- lapply(pages, function(pages) html_nodes(pages, "div.ecl p"))
names_speech <- lapply(pages, function(pages) html_nodes(pages, "div.ecl h3"))

# Convert them into text
descriptions_speech <- lapply(descriptions_speech, html_text)
names_speech <- lapply(names_speech, html_text)

# Clean the element of description (there is extra info)
descriptions_speech <- lapply(descriptions_speech, function(x) x[!grepl("Address \\| Video", x)])

# Unlist element to save them in a ddf
descriptions_speech <- unlist(descriptions_speech)
names_speech <- unlist(names_speech)

# And add these keywords to a matrix to save them
temp_df <- data.frame(name_speech = names_speech, main_topics = descriptions_speech)
df <- bind_rows(df, temp_df)

# Create new columns year and speech_text
df <- df %>% mutate(year = sub(".*\\b(\\d{4})$", "\\1", name_speech),
                    speech_text = NA)
df

```

```{r save data}
# We save the data to avoid calling the scrapper all the time
save.image("df_keywords.RData")

```

Our scraping results illustrate an evolution of main topics over time.

Initial speeches primarily focused on the economic condition of the European Union. This then shifted to discussions about economic recovery, intertwined with the migration crisis and investment across various industries. More recent speeches have pivoted to addressing the COVID-19 pandemic, health issues, and the conflict in Ukraine.


#### 3. Preprocessing

Firstly, as previously mentioned, we manually downloaded the PDF files of interest, which are included alongside this notebook. This step was taken to ensure the quality and suitability of our text.

We noted that some PDFs contained extra information, irrelevant to our purposes, which varied depending on the document's format. This unnecessary information, which is not pertinent to our analysis, include:

- Speech covers
- Page numbers
- Titles and subtitles
- Preambles
- Images
- Closing statements

We've made efforts to clean the text to preserve as much of the actual spoken speech as possible.

```{r readpdfs}
path_to_folder <- "./PDFs/"

pdf_files <- list.files(path = path_to_folder, pattern = "\\.pdf", full.names = TRUE)

for (pdf_file in pdf_files){
  pdf_speech <- pdf_text(pdf_file)
  par_year <- regmatches(pdf_speech, regexpr("September\\s*(\\d{4})|STATE OF THE UNION\\s*(\\d{4})", pdf_speech))
  par_year <- par_year[1]
  par_year <- str_sub(par_year,-4,-1)

  # pdf_text returns an element for each page, we already know that the 2016 document include more texts than the speech. Even if we can erase the rest of the text in a later step, for simplicity we will do it now
  
  if(par_year == "2016"){pdf_speech <- pdf_speech[1:22]}
  
  # Clean the page number (easier to do it before the merging of pages)
  pdf_speech <- sub("\\s*\\d+\\s*(\\n)+$", " ", pdf_speech)
  
  # Clean the header if exist
  pdf_speech <- sub("^\\s*State of the Union [0-9]{4}\\s*.*?\\n{4,}", "\n", pdf_speech, ignore.case = TRUE, perl = TRUE)
  
  # Collapse the pages
  speech_joint <- paste(pdf_speech, collapse =" ")
  
  # Clean 's
  speech_joint <- gsub("’s|'s", " ", speech_joint, ignore.case = TRUE)
  
  # Clean titles (2015 is not possible because our expression eraised part of the speech)
  if (par_year %in% c("2012")){
    speech_joint <- gsub("\\n{2,}\\d+\\s*\\.[A-Za-z:\\s'\\-\\—\\–]+\\n|\\n{2,}\\s*[a-z]\\) [A-Za-z\\s:'\\-\\—\\–]+\\n", "\n", speech_joint, perl = TRUE)
    }
  else if (par_year %in% c("2016","2017","2018","2020")){
    speech_joint <- gsub("\\n{1,}[A-Z:\\-\\—\\–\\s]+\n{1,}", "\n", speech_joint, perl = TRUE) 
  }
  else if (par_year %in% c("2021","2022")){
    speech_joint <- gsub("\\n{3,}[A-Z][A-Za-z\\s]+\\n{1,}", "\n", speech_joint, perl = TRUE) 
  }
  
  # Clean punctuation
  speech_joint <- gsub("[[:punct:]]", " ", speech_joint)
  
  # Clean preamble
  speech_joint <- sub(".*?(Mr President|Dear President|President \nHonourable Members|Mr  President)", " ", speech_joint)

  # Clean finisher
  speech_joint <- sub("(SPEECH|Updated version following delivery|For further information| Jean Claude Juncker).*", "", speech_joint)
  
  # Clean repetitive addresses to public
  speech_joint <- gsub("Presidency of the Council|Madam President of the Council|Dear Mr President|Dear President|Mr President|Madam President|Honourable Members of the European Parliament|Honourable Members|Honourable members|Minister|Ladies and Gentlemen|Ladies and gentlemen|My fellow Europeans|My dear colleagues", " ", speech_joint)
  
  # Clean spaces
  speech_joint <- gsub("\\s+", " ", speech_joint)
  
  # Match the speech with its year
  df$speech_text[df$year == par_year] <- speech_joint
  
}

df <- as_tibble(df)
df

```

In addition to the situations mentioned earlier, we further cleaned the text by removing punctuation and extra spaces before saving it to our dataframe. We would like to bring attention to some issues that arose during this process:

- The 2016 speech includes some images with text that is read by the 'read_pdf' command. We attempted to remove this, but it proved challenging without discarding portions of the speech that are relevant to our analysis. Consequently, we opted to retain this additional text. Since the images are related to the speech, they should not significantly skew our analysis of the speech's primary topic.

- We made a deliberate choice to remove certain frequently repeated words that did not contribute valuable information for our purposes. Phrases such as "Mr President" and "Honourable members" appear so frequently in the speeches that they could potentially confuse topic models by appearing as significant topics.

- Additionally, we decided to eliminate the contraction "'s" as it does not contribute significantly to topic selection.

To complete the preprocessing of our texts, we tokenized, lemmatized, and removed stopwords to refine our results.

```{r textstem}

custom_stopwords = c(stopwords("en"))

speech_tokens <- df$speech_text %>%  tolower() %>%
                        lemmatize_strings() %>%
                        corpus() %>%
                        quanteda::tokens() %>%
                        quanteda::tokens_remove(custom_stopwords)

speech_tokens

```


### 4. Descriptive Analysis

Before the application of the topic models, it would be beneficial to examine in greater detail the text data we have extracted from the speeches.

Initially, we will visualize the most frequently used words across all speeches. This exploration may provide valuable insights to guide us in determining the number of topics to be identified in subsequent steps or indicate if our data requires further refinement.

```{r}

dfm_matrix <- speech_tokens %>% dfm()

textstat_frequency(dfm_matrix)[c(1:50),]

tail(textstat_frequency(dfm_matrix), 50)

```

Many of the most frequent words in our dataset do not substantially contribute to understanding the main topics of the speeches. These words are often more related to the intent or style of a speech rather than the core message. For example, the words "must" and "can" are typically used to express present or future intent, an expected finding since one of the primary functions of these speeches is to outline priorities for the upcoming year. Moreover, terms such as "europe", "european", and "union" are prevalent due to the inherent context of the speech, yet they do not necessarily elucidate the central topics.

Such observations prompt us to eliminate some of the most commonly occurring, yet non-informative, words from the text.

```{r}

custom_stopwords = c(stopwords("en"), "europe", "european","eu","much","can","state","union","make","year","also","must","need","commission", "member")

new_tokens <- speech_tokens %>% 
              quanteda::tokens_remove(custom_stopwords)

new_dfm <- new_tokens %>% dfm()

textstat_frequency(new_dfm)[c(1:50),]

```

Now, with our refined bag of words, we will conclude our descriptive analysis by creating a word cloud for each speech. This will allow us to visually represent the most prominent ideas expressed in each individual speech.

```{r wordcloud for each speech}

# Assuming df is your data frame and speech_text is the column containing speeches
for (i in 1:length(new_tokens)){
  
  dfm_matrix <- new_tokens[i] %>% dfm()
  textplot_wordcloud(dfm_matrix, max_words = 35)
  title(main = paste("Word Cloud for State of the Union", df$year[i]))
}

```

From the word clouds, we can observe apparent differences between speeches:

- 2022: The focus is primarily on "ukraine" and related terms ("war", "crisis", "ukrainian", "russia"). There are also words connected to the "economy" ("price", "gas"), along with "democracy", and some words that are more ambiguous in their classification such as "solidarity", "future", "global", "people", "support".

- 2021: Frequent words include some generic terms ("new", "time", "world", "global", "work", "together"), economic terms ("market", "investment"), and the words "pandemic", "freedom", and "climate", which all could be linked to the generic words.

- 2020: Again, generic words like "world", "want", "work", and "people" appear, in addition to some words indirectly related to the pandemic ("digital", "strong", "together").

- 2018: Repeated words include more ambiguous ones ("world", "good", "today"), economic terms ("investment","trade"), and new words like "election", "Africa", and "border", to name a few.

- 2017: Frequently seen words are "want", "good", "work", "now", "new", etc. Identifying clear connections among words in this speech is challenging.

- 2016: Frequent words include "work", "get", "take", "job", "parliament", etc. Establishing clear connections among words in this speech is also difficult.

- 2015: Some recurring themes like "greece", "euro", and "crisis" are present, along with a clear new cluster of "refugee" ("asylum") and the words "policy" and "climate".

- 2013: The main words are "crisis", "one". The economic cluster of words ("market", "euro", "economy", "economic") is very prominent.

- 2012: The word "political" is predominant, along with clusters of ideas related to "economics" ("bank","market","euro") and "reform" ("change", "decision", "way").

- 2011: The focus is on "economic/economy"-related words ("market", "growth", "financial"), with related terms such as "euro" and "greece".

- 2010: This speech primarily contains words related to economics ("budget", "financial", "growth", "job", "market").

Overall, we see that all speeches maintain an economic aspect, which is noticeably more prominent in older speeches (2010-2012) and the most recent speech (2022). Additionally, we observe a cluster of words related to migration ("refugee", "border") appearing in 2015 and 2018, fading in 2020 with the advent of COVID-19 and the war in Ukraine (and their associated economic crises). The speeches from 2016 and 2017 present some challenges when it comes to precise topic identification.

Despite these observations, our findings are consistent with the main themes extracted from the official websites and recent European history.

We have intentionally excluded certain words, such as "us", from our analysis because of their potential multiple meanings. Additionally, the word cloud reveals potential issues with our text cleaning process. For instance, the words "t", "1", and "2" occasionally appear in the clouds, along with nearly identical terms like "economic" and "economy". A more thorough explanation is provided in the Validation section.


```{r savecsv}
# Save the data 
save.image("df_keywords.RData")

```


#### 5. Topic Modeling

One of the most widely used techniques for topic modeling is the Latent Dirichlet Allocation (LDA) model. LDA is a mixture model; in other words, it assumes that each document is a mixture of topics, and each topic is a blend of words that are not exclusive to that topic. Given these assumptions, the model strives to determine the topic for each word in the documents.

In this section, we adopt code from Van Atteveldt, W., et al. (2022, Chapter 11) for the implementation of the LDA model and the search for hyperparameters. We also used code from Silge J. & Robinson D. (2017, Chapter 6) for the visualization of the words per topic.

Initially, we opted to execute a grid search to determine the optimal number of topics (k). We set the value of alpha to an asymmetric vector following the formula alpha = 1/(n + sqrt(k)) (Van Atteveldt, W., et al., 2022, Chapter 11)), where 'n' ranges from 1 to k. Our choice for an asymmetrical alpha stems from the expectation that certain topics may appear more frequently in specific speeches than in others. For instance, should the topics "pandemic" or "health" arise, we anticipate these to be more prevalent in the three most recent speeches (2020-2022) compared to the others.

We fitted our LDA models using different values of k, ranging from 3 to 30. While this range might seem arbitrary, it is justified considering that the maximum number of keywords scraped from the main topics is 9. If we interpret each keyword as a topic, the range is sufficient for finding an optimal quantity of topics. The metrics we will use to define this optimal point are Perplexity and Coherence of the model. Perplexity evaluates how well the model predicts the word distribution, and Coherence assesses the semantic cohesiveness of the topics. In general, we are seeking the model that minimizes both these metrics.

```{r LDA}
# LDA for all speeches together (this takes minutes to run, beware)

# Create vector for k
k_lda <- seq(3,30)
results <- list()

dfm_matrix <- new_tokens %>% dfm()
dtm <- dfm_matrix %>% convert(to = "topicmodels")


# Loop to test configuration of hyperparameters
for (k in k_lda){
  
  iteration_results <- list()
  alpha = 1/((1:k)+sqrt(k))
  
  for (i in 1:10){

  cat("Model k=", k, " iteration=", i, "\r")
  
  lda_model <- dfm_matrix %>%
               convert(to = "topicmodels") %>% 
               LDA(k=k, control = list(alpha=alpha))
  
  iteration_results[[as.character(i)]] <- data.frame(
                              perplexity = perplexity(lda_model),
                              coherence = mean(topic_coherence(lda_model, dtm)))
  
  }
  
  avg_perplexity <- mean(sapply(iteration_results, function(x) x$perplexity))
  avg_coherence <- mean(sapply(iteration_results, function(x) x$coherence))
  
  results[[as.character(k)]] <- data.frame(
                                perplexity <- avg_perplexity,
                                coherence <- avg_coherence)

}

bind_rows(results, .id="k") %>% 
  mutate(k=as.numeric(k)) %>%
  pivot_longer(-k) %>% 
  ggplot() + 
  geom_line(aes(x=k, y=value)) + 
  xlab("Number of topics") + 
  facet_grid(name ~ ., scales="free")

 
```

We can see that the model with the lowest value in both metrics is k=17. Once we define the model we will use, we can check the topics extracted.


```{r}
k <- 17

lda_k17 <- dfm_matrix %>%
           convert(to = "topicmodels") %>% 
           LDA(k=k, control = list(seed=0, alpha=1/((1:k)+sqrt(k))))

terms(lda_k17, 10)

```

When we are interpreting topics from our model certain topics are quite apparent.

For instance, Topic 3 is clearly about Ukraine and its ongoing war. Topics 7, 8, 10, and 11 concern economic matters, but from different perspectives. Topic 7 appears to focus on the growth of the internal EU market, while Topic 8 seems to address policy or reforms following an economic crisis. Topic 10 seemingly centers around protecting investment during a crisis in the eurozone, and Topic 11 looks to be related to economic growth, particularly in response to a crisis.

Another clearly distinguishable topic is Topic 15, which pertains to the refugee crisis. This could potentially refer to the lasting effects of the euro economic crisis in Greece or the refugee crisis specifically affecting Greece.

The remaining topics are somewhat ambiguous, making interpretation challenging. A clear central idea does not readily emerge from the associated bag of words.

```{r savecsv}
# Save the data 
save.image("checkpointLDA.RData")

```


#### 6. Validation

To validate we have three roads:
- Compare multiple models
- Compare each model with the keywords from the website
- Manual checking





```{r}

  # Create the empty dataframe to store columns
  df <- data.frame(matrix(nrow=0, ncol=k))
  colnames(df) <- paste0("Topic", 1:k)
  
  for (alpha in alpha_lda){
    # Check is running
    cat("Model k=", k, " alpha=", alpha, "\r")
    
    # Model training
    lda_model <- new_tokens %>% dfm() %>% 
                 convert(to = "topicmodels") %>% 
                 LDA(k=k, control = list(seed=0, alpha=alpha))
    
    # Get the topics and store them in the dataframe
    topic_words <- paste(terms(lda_model), collapse = "-")
    topics_df <- data.frame(matrix(matrix(strsplit(topic_words, "-")[[1]]), nrow=1, ncol=k))
    colnames(topics_df) <- colnames(df)
    
    # Add alpha
    rownames(topics_df) <- paste0("alpha_", alpha)
    
    # Bind the results with the summary table
    df <- rbind(df, topics_df)
  }
  
  print(df)

lda_models


dfm_matrix <- new_tokens %>% dfm()

lda <- dfm_matrix %>% convert(to = "topicmodels") %>% 
         LDA(k=5, control = list(seed=0, alpha=1/c(1:10)))

terms(lda)

test <- paste(terms(lda), collapse="-")
test

ap_top_terms <- tidy(lda, matrix = "beta") %>%
                group_by(topic) %>%
                slice_max(beta, n=10) %>%
                ungroup() %>%
                arrange(topic, -beta) 
                
ap_top_terms %>% mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()



ap_documents <- tidy(lda, matrix = "gamma")
ap_documents

ap_wide <- ap_documents %>% 
           unite(topic, topic, sep=" ", remove=FALSE) %>%
           spread(key=topic, value=gamma)
ap_wide$doc_num <- as.numeric(gsub("text", "", ap_wide$document))
ap_wide <- ap_wide[order(ap_wide$doc_num), ]
ap_wide$doc_num <- NULL

num_cols <- which(sapply(ap_wide, is.numeric))  # Find the columns which are numeric
ap_wide[, num_cols] <- round(ap_wide[, num_cols], 3)

ap_wide 

```


```{r}

for (i in 1:length(new_tokens)){
  
  dfm_matrix <- new_tokens[i] %>% dfm()
  lda <- dfm_matrix %>% convert(to = "topicmodels") %>% 
         LDA(k=5, control = list(seed=0, alpha=1/c(1:10)))

  print(terms(lda))
}


```


DTM

```{r}

```

HDP

```{r}

```

CTM

```{r}

```




#### 6. Validation

To validate we have three roads:
- Compare multiple models
- Compare each model with the keywords from the website
- Manual checking

```{r}

```



#### 7. Conclusions

()



#### 8. Elevator Pitch






#### 9. References

State of the Union addresses. (n.d.). State of the Union. https://state-of-the-union.ec.europa.eu/index_en

Framework Agreement on relations between the European Parliament and the European Commission, EP, 304 OJ L (2010). http://data.europa.eu/eli/agree_interinstit/2010/1120/oj/eng

von der Leyen, U. (n.d.). State of the Union Address 2022. State of the Union . https://state-of-the-union.ec.europa.eu/system/files/2023-06/SOTEU_2022_Address_EN.pdf 

von der Leyen, U. (n.d.-a). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_21_4701 

von der Leyen, U. (n.d.-b). State of the Union Address 2020. State of the Union 2020. https://state-of-the-union.ec.europa.eu/system/files/2022-08/soteu_2020_en.pdf 

Juncker, J. C. (n.d.). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/speech_18_5808 

Juncker, J. C. (n.d.-b). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_17_3165 

European Commission, Directorate-General for Communication, Juncker, J. (2016). State of the Union 2016 – , Publications Office of the European Union. https://data.europa.eu/doi/10.2775/968989

Juncker, J. C. (n.d.-c). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_15_5614 

Barroso, J. M. (n.d.). Press corner. European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_13_684

Barroso, J. M. (n.d.-b). Press corner.European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_12_596

Barroso, J. M. (n.d.-c). Press corner.European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_11_607

Barroso, J. M. (n.d.-d). Press corner.European Commission - European Commission. https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_10_411

Van Atteveldt, W., Trilling, D., & Calderón, C. A. (2022). Computational Analysis of Communication. Wiley Blackwell. Retrieved June 18 2023 from https://cssbook.net/content/chapter11.html#sec-beyondlda 

Silge J. & Robinson D. (2017). Text mining with r : a tidy approach (First). O'Reilly Media. Retrieved June 18 2023 from https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=1533983.








